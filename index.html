<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mastering Retrieval-Augmented Language Model: Unlocking Advanced Retrieval Techniques</title>
    <link rel="stylesheet" href="index.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
</head>

<body>
    <header>
        <h1>Mastering Retrieval-Augmented Generation: Unlocking Advanced Retrieval Techniques</h1>
        <h3>ROCLING 2024 - November 4, 2024</h3>
    </header>

    <section id="overview">
        <h2>Overview</h2>
        <p style="text-align: left;">
            In this tutorial, we explore the critical role of Retrieval-Augmented Language Models (RALMs) in enhancing large language model's knowledge retrieval capabilities. Starting with an overview of their importance, weâ€™ll trace the evolution of core retrieval techniques from 2014 to present, covering milestones including word2vec, S-BERT, ICT, DPR, REALM, ColBERT, GAR, HyDE, and LLM Embeddings. Participants will gain a foundational understanding of how each method contributed to retrieval advancements and acquire practical insights into leveraging these techniques to improve model efficiency and precision in real-world applications.
        </p>
    </section>

    <section id="presenters">
        <h2>Presenters</h2>
        <h2>Members from NLP Lab, NCHU, Taiwan</h2>
        <div class="avatar-container">
            <div class="avatar">
                <img src="fan.jpg" alt=" Yao-Chung Fan">
                <p><strong>Yao-Chung Fan</strong></p>
                <div class="social-icons">
                    <!-- <a href="" target="_blank"><i class="fab fa-github"></i></a> -->
                    <!-- <a href="" target="_blank"><i class="fab fa-linkedin"></i></a> -->
                    <a href="https://yfan.nlpnchu.org/" target="_blank"><i class="fas fa-home"></i></a>
                </div>
            </div>
            <div class="avatar">
                <img src="ssw.jpg" alt="Sin-Syuan Wu">
                <p><strong>Sin-Syuan Wu</strong></p>
                <div class="social-icons">
                    <a href="https://github.com/SinSuan" target="_blank"><i class="fab fa-github"></i></a>
                    <a href="https://www.linkedin.com/in/%E6%AC%A3%E7%92%87-%E5%90%B3-617786317/" target="_blank"><i class="fab fa-linkedin"></i></a>
                    <!-- <a href="" target="_blank"><i class="fas fa-home"></i></a> -->
                </div>
            </div>
            <div class="avatar">
                <img src="wang.jpg" alt="Yen-Hsiang Wang">
                <p><strong>Yen-Hsiang Wang</strong></p>
                <div class="social-icons">
                    <a href="https://github.com/kenny75557" target="_blank"><i class="fab fa-github"></i></a>
                    <a href="https://www.linkedin.com/in/heliart/" target="_blank"><i class="fab fa-linkedin"></i></a>
                    <a href="https://heliart.me/" target="_blank"><i class="fas fa-home"></i></a>
                </div>
            </div>
            <div class="avatar">
                <img src="wei.jpg" alt="Che-Wei Chang">
                <p><strong>Che-Wei Chang</strong></p>
                <div class="social-icons">
                    <a href="https://github.com/allen3325" target="_blank"><i class="fab fa-github"></i></a>
                    <a href="https://www.linkedin.com/in/allen-chang-baomovie" target="_blank"><i class="fab fa-linkedin"></i></a>
                    <a href="https://allen3325.github.io/" target="_blank"><i class="fas fa-home"></i></a>
                </div>
            </div>
        </div>
    </section>

    <section>
        <img src="IRAdvance.png" alt="IR Advance" style="width: 100%; display: block;">
    </section>
    

    <section id="reading-list">
        <h2>Reading List</h2>
        <p>We encourage participants to go through the following readings before attending the tutorial:</p>
        <ul>
            <li><a href="https://arxiv.org/abs/1906.00300" target="_blank">Latent Retrieval for Weakly Supervised Open Domain Question Answering</a>(Lee et al., 2019)</li>
            <li><a href="https://arxiv.org/abs/2002.08909" target="_blank">REALM: Retrieval-Augmented Language Model Pre-Training</a>(Guu et al., 2020)</li>
            <li><a href="https://arxiv.org/abs/2004.04906" target="_blank">Dense Passage Retrieval for Open-Domain Question Answering</a>(Karpukhin et al., 2020)</li>
            <li><a href="https://arxiv.org/abs/2104.08253" target="_blank">Condenser: a Pre-training Architecture for Dense Retrieval</a>(Gao & Callan, 2021; 2022)</li>
            <li><a href="https://arxiv.org/abs/2004.12832" target="_blank">ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT</a>(Khattab & Zaharia, 2020)</li>
            <li><a href="https://arxiv.org/abs/2102.07033" target="_blank">PAQ 65 Million Probably-Asked Questions and What You Can Do With Them</a>(Lewis et al., 2020)</li>
            <li><a href="https://arxiv.org/abs/2009.08553" target="_blank">Generation-Augmented Retrieval for Open-Domain Question Answering</a>(Mao et al., 2020)</li>
            <li><a href="https://arxiv.org/abs/2212.10496" target="_blank">Precise Zero-Shot Dense Retrieval without Relevance Labels</a>(Gao et al. 2022)</li>
            <li><a href="https://arxiv.org/abs/2305.14283" target="_blank">Query Rewriting for Retrieval-Augmented Large Language Models</a>(Ma et al., 2023)</li>
            <li><a href="https://arxiv.org/abs/2401.00368" target="_blank">Improving Text Embeddings with Large Language Models</a>(Wang et al., 2023)</li>
        </ul>
    </section>

    

    <footer>
        <p>For more information, please refer to our laboratory website <a href="https://nlpnchu.org/">National Chung Hsing University - Natural Language Processing Lab</a></p>
    </footer>
</body>
</html>
